{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# Load POS and DEP mappings\n",
    "def load_mappings(dep_path, pos_path):\n",
    "    with open(dep_path) as f:\n",
    "        dep_mapping = json.load(f)\n",
    "    with open(pos_path) as f:\n",
    "        pos_mapping = json.load(f)\n",
    "    return dep_mapping, pos_mapping\n",
    "\n",
    "# Custom dataset class\n",
    "class CustomRAGDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, dep_mapping, pos_mapping, max_length=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.dep_mapping = dep_mapping\n",
    "        self.pos_mapping = pos_mapping\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        question = item['question']\n",
    "        tokenized_input = self.tokenizer(question, truncation=True, padding='max_length', max_length=self.max_length)\n",
    "\n",
    "        dep_tags = self.dep_mapping.get(item['id'], [])\n",
    "        pos_tags = self.pos_mapping.get(item['id'], [])\n",
    "\n",
    "        # Padding dep and pos tags if necessary\n",
    "        dep_tags = dep_tags[:self.max_length] + [0] * (self.max_length - len(dep_tags))\n",
    "        pos_tags = pos_tags[:self.max_length] + [0] * (self.max_length - len(pos_tags))\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(tokenized_input['input_ids']),\n",
    "            'attention_mask': torch.tensor(tokenized_input['attention_mask']),\n",
    "            'dep_tags': torch.tensor(dep_tags),\n",
    "            'pos_tags': torch.tensor(pos_tags),\n",
    "            'answer': torch.tensor(item['answer'])  # Assuming answer is already tokenized or can be\n",
    "        }\n",
    "\n",
    "# Load dataset\n",
    "def load_dataset(data_path):\n",
    "    with open(data_path) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# Example usage\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openlm-research/open_llama_7b_v2\", use_fast=False)\n",
    "\n",
    "dep_mapping, pos_mapping = load_mappings('path/to/dep_mapping.json', 'path/to/pos_mapping.json')\n",
    "dataset = load_dataset('path/to/dataset.json')\n",
    "\n",
    "# Create dataset and dataloaders\n",
    "train_dataset = CustomRAGDataset(dataset, tokenizer, dep_mapping, pos_mapping)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=4)  # Adjust batch_size as needed\n",
    "\n",
    "# Example usage in training loop\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openlm-research/open_llama_7b_v2\")\n",
    "model.to('cuda')  # Assuming you have a GPU\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(3):  # Example: 3 epochs\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to('cuda')\n",
    "        attention_mask = batch['attention_mask'].to('cuda')\n",
    "        dep_tags = batch['dep_tags'].to('cuda')\n",
    "        pos_tags = batch['pos_tags'].to('cuda')\n",
    "        labels = batch['answer'].to('cuda')\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, eval_dataloader):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    for batch in eval_dataloader:\n",
    "        with torch.no_grad():\n",
    "            input_ids = batch['input_ids'].to('cuda')\n",
    "            attention_mask = batch['attention_mask'].to('cuda')\n",
    "            dep_tags = batch['dep_tags'].to('cuda')\n",
    "            pos_tags = batch['pos_tags'].to('cuda')\n",
    "            labels = batch['answer'].to('cuda')\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "    avg_eval_loss = eval_loss / len(eval_dataloader)\n",
    "    print(f\"Average Evaluation Loss: {avg_eval_loss}\")\n",
    "\n",
    "# Example evaluation\n",
    "eval_dataset = CustomRAGDataset(dataset, tokenizer, dep_mapping, pos_mapping)\n",
    "eval_sampler = SequentialSampler(eval_dataset)\n",
    "eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=4)\n",
    "\n",
    "evaluate_model(model, eval_dataloader)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
